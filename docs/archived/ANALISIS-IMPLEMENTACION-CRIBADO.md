# üìã An√°lisis de Implementaci√≥n: Fase de Cribado

**Fecha:** 3 de Diciembre, 2025  
**Comparaci√≥n:** Requerimientos del Docente vs Implementaci√≥n Actual

---

## üéØ Resumen Ejecutivo

Este documento analiza el estado actual del sistema de cribado compar√°ndolo con los 4 pasos requeridos por el docente. Se identifican funcionalidades **YA IMPLEMENTADAS** ‚úÖ, **PARCIALMENTE IMPLEMENTADAS** ‚ö†Ô∏è y **FALTANTES** ‚ùå.

### Estado General por Fase

| Fase | Estado | Completitud | Prioridad |
|------|--------|-------------|-----------|
| **Fase 1: Eliminar Duplicados** | ‚úÖ COMPLETO | 95% | Baja |
| **Fase 2: Screening (T√≠tulo/Resumen)** | ‚ö†Ô∏è PARCIAL | 70% | **ALTA** |
| **Fase 3: Full Screening (Texto Completo)** | ‚ö†Ô∏è PARCIAL | 40% | **CR√çTICA** |
| **Fase 4: An√°lisis de Resultados** | ‚ö†Ô∏è PARCIAL | 60% | Media |

---

## üìä FASE 1: Eliminar Duplicados

### ‚úÖ YA IMPLEMENTADO

**Archivo:** `backend/src/domain/use-cases/detect-duplicates.use-case.js`

#### Algoritmos Implementados:

1. **‚úÖ Coincidencia por DOI (Prioridad 1)**
   ```javascript
   // Normaliza DOI y compara
   _normalizeDOI(doi) {
     return doi.toLowerCase().replace(/https?:\/\/(dx\.)?doi\.org\//gi, '').trim();
   }
   ```
   - ‚úÖ Elimina prefijos HTTP
   - ‚úÖ Case-insensitive
   - ‚úÖ Identifica como duplicado si DOI coincide

2. **‚úÖ Coincidencia por T√≠tulo + Similitud (Prioridad 2)**
   ```javascript
   _calculateSimilarity(title1, title2) {
     const distance = this._levenshteinDistance(t1, t2);
     const similarity = ((maxLength - distance) / maxLength) * 100;
   }
   ```
   - ‚úÖ Normaliza t√≠tulos (lowercase, sin acentos, sin caracteres especiales)
   - ‚úÖ Algoritmo de Levenshtein implementado
   - ‚úÖ Umbral de 90% para duplicado exacto
   - ‚úÖ Umbral de 85% + autores coincidentes

3. **‚úÖ Comparaci√≥n de Autores**
   ```javascript
   _sameAuthors(authors1, authors2) {
     // Normaliza y compara conjuntos
     // Si >= 50% autores coinciden ‚Üí duplicado
   }
   ```

4. **‚úÖ Acciones Implementadas**
   - Marca referencias como `status: 'duplicate'`
   - Agrupa duplicados manteniendo el original con m√°s metadatos
   - Genera reporte con grupos de duplicados

5. **‚úÖ Frontend**
   - Componente: `frontend/components/screening/duplicate-detection-dialog.tsx`
   - Bot√≥n "Detectar Duplicados" en UI
   - Di√°logo mostrando grupos y pares detectados
   - Estad√≠sticas: total, √∫nicos, duplicados, grupos

### ‚ö†Ô∏è MEJORAS RECOMENDADAS

1. **Prioridad de Metadatos**: Implementar l√≥gica que conserve referencia con:
   - Abstract presente > sin abstract
   - PDF disponible > sin PDF
   - M√°s campos completos

2. **Exportaci√≥n**: Crear `duplicates.csv` con:
   ```csv
   id_kept,id_removed,similarity_score,reason,doi_match,title_match
   ```

3. **Normalizaci√≥n T√≠tulo + Autor + A√±o**: A√±adir verificaci√≥n:
   ```javascript
   if (similarity >= 80 && sameYear && firstAuthorMatch) {
     return true; // duplicado
   }
   ```

### üìà Completitud: **95%**

**Lo que falta:**
- ‚ùå Exportar CSV de duplicados
- ‚ùå L√≥gica expl√≠cita de "mejor metadato"
- ‚ùå Coincidendia t√≠tulo+autor+a√±o normalizado

---

## üìä FASE 2: Screening (T√≠tulo/Resumen) - Limpieza R√°pida

### ‚úÖ YA IMPLEMENTADO

**Archivos:**
- `backend/src/domain/use-cases/run-project-screening.use-case.js`
- `backend/src/domain/use-cases/screen-references-embeddings.use-case.js`
- `backend/src/domain/use-cases/screen-references-with-ai.use-case.js`

#### 1. **Sistema H√≠brido IMPLEMENTADO** ‚úÖ

```javascript
// FASE 1: Embeddings para clasificaci√≥n r√°pida
executeHybrid({ projectId, protocol, embeddingThreshold = 0.15 }) {
  // Clasifica:
  // - similarity >= 30% ‚Üí Alta confianza INCLUIR
  // - similarity <= 10% ‚Üí Alta confianza EXCLUIR  
  // - 10-30% ‚Üí Zona gris (env√≠a a ChatGPT)
}
```

**Caracter√≠sticas:**
- ‚úÖ Modelo: `all-MiniLM-L6-v2` (384 dims)
- ‚úÖ Similitud coseno entre embeddings
- ‚úÖ Umbral ajustable (recomendado: 15% para ingl√©s-espa√±ol)
- ‚úÖ An√°lisis de distribuci√≥n con m√©todo Elbow (RECI√âN IMPLEMENTADO)
- ‚úÖ Estad√≠sticas autom√°ticas (percentiles, mean, median, std dev)

#### 2. **An√°lisis con LLM para Zona Gris** ‚úÖ

```javascript
// FASE 2: ChatGPT/Gemini analiza solo zona gris
if (greyZone.length > 0) {
  const llmResult = await this.screenAIUseCase.executeBatch({
    references: greyZoneRefs,
    protocol,
    provider: aiProvider // 'chatgpt' o 'gemini'
  });
}
```

**Caracter√≠sticas:**
- ‚úÖ Razonamiento contextual completo
- ‚úÖ Evaluaci√≥n de criterios PICO
- ‚úÖ Explicaciones detalladas por referencia
- ‚úÖ Confidence score (0-1)

#### 3. **Frontend Implementado** ‚úÖ

**Componentes:**
- `frontend/components/screening/ai-screening-panel.tsx` - Panel de control
- `frontend/components/screening/similarity-distribution-analysis.tsx` - An√°lisis Elbow
- `frontend/components/screening/hybrid-screening-stats.tsx` - Estad√≠sticas
- `frontend/components/screening/reference-table.tsx` - Tabla de referencias

**Flujo UI:**
1. Usuario ejecuta "An√°lisis de Distribuci√≥n" ‚Üí Ve punto de corte √≥ptimo
2. Acepta umbral recomendado ‚Üí Slider se actualiza autom√°ticamente
3. Ejecuta "Cribado H√≠brido" ‚Üí Embeddings + ChatGPT
4. Ve resultados: incluidos, excluidos, zona gris analizados

### ‚ö†Ô∏è PARCIALMENTE IMPLEMENTADO

#### 1. **Filtrado por T√©rminos del Protocolo** ‚ö†Ô∏è

**Estado Actual:**
- ‚úÖ Protocolo genera `keyTerms` (technologies, applicationDomain, studyType, thematicFocus)
- ‚úÖ Se usan en embeddings para calcular similitud sem√°ntica
- ‚ùå **NO hay filtro boolean expl√≠cito** con INCLUDE/EXCLUDE keywords

**Lo que falta implementar:**

```javascript
// NUEVO: Filtro boolean basado en t√©rminos
class KeywordScreeningUseCase {
  execute({ reference, protocol }) {
    const { inclusionCriteria, exclusionCriteria, keyTerms } = protocol;
    
    // Construir listas de keywords
    const includeKeywords = this._extractKeywords(inclusionCriteria, keyTerms);
    const excludeKeywords = this._extractKeywords(exclusionCriteria, keyTerms);
    
    // Tokenizar t√≠tulo + abstract
    const text = `${reference.title} ${reference.abstract}`.toLowerCase();
    
    // Verificar exclusiones (prioridad alta)
    for (const kw of excludeKeywords) {
      if (text.includes(kw)) {
        return { decision: 'exclude_auto', reason: `Keyword exclusi√≥n: ${kw}` };
      }
    }
    
    // Verificar inclusiones
    const includeMatches = includeKeywords.filter(kw => text.includes(kw));
    if (includeMatches.length >= 2) { // Al menos 2 keywords
      return { decision: 'include_auto', reason: `Keywords matched: ${includeMatches}` };
    }
    
    // Sin coincidencias claras
    return { decision: 'manual_review', reason: 'No clear keyword match' };
  }
}
```

#### 2. **UI para Revisi√≥n Manual con T√©rminos Resaltados** ‚ö†Ô∏è

**Actual:**
- ‚úÖ Componente `individual-review-enhanced.tsx` existe
- ‚úÖ Muestra t√≠tulo, abstract, autores, a√±o
- ‚úÖ Botones Incluir/Excluir con motivos
- ‚ùå **NO resalta t√©rminos matched** del protocolo

**Mejora Requerida:**

```tsx
// Funci√≥n para resaltar keywords en abstract
function highlightKeywords(text: string, keywords: string[]) {
  let highlighted = text;
  keywords.forEach(kw => {
    const regex = new RegExp(`(${kw})`, 'gi');
    highlighted = highlighted.replace(regex, '<mark class="bg-yellow-200">$1</mark>');
  });
  return highlighted;
}

// En el componente:
<div dangerouslySetInnerHTML={{ 
  __html: highlightKeywords(reference.abstract, matchedKeywords) 
}} />
```

#### 3. **M√©tricas de Concordancia** ‚ö†Ô∏è

**Actual:**
- ‚úÖ `analyze-screening-results.use-case.js` calcula:
  - Total procesados
  - Por estado (pending, included, excluded)
  - Con/sin IA
  - Avg confidence, avg similarity
  - **Disagreements** (cuando humano difiere de IA)
- ‚ùå **NO calcula % de concordancia** entre auto-match y decisi√≥n humana

**Agregar:**

```javascript
// En analyze-screening-results.use-case.js
stats.concordance = {
  autoMatchCorrect: 0,    // Humano confirm√≥ recomendaci√≥n IA
  autoMatchIncorrect: 0,  // Humano cambi√≥ decisi√≥n IA
  concordanceRate: 0      // % de acuerdo
};

// Calcular para cada referencia con IA:
if (ref.ai_recommendation && ref.screening_status !== 'pending') {
  if (ref.ai_recommendation === ref.screening_status) {
    stats.concordance.autoMatchCorrect++;
  } else {
    stats.concordance.autoMatchIncorrect++;
  }
}

stats.concordance.concordanceRate = 
  ((stats.concordance.autoMatchCorrect / stats.withAI) * 100).toFixed(1);
```

### üìà Completitud: **70%**

**Prioridad ALTA - Implementar:**
1. ‚ùå Filtro boolean por keywords (INCLUDE/EXCLUDE)
2. ‚ùå Resaltar t√©rminos matched en UI
3. ‚ùå M√©trica de concordancia auto-match vs humano
4. ‚ùå Categorizaci√≥n autom√°tica por tipo de estudio (si aplica PICO)

---

## üìä FASE 3: Full Screening (Texto Completo) - Limpieza Profunda

### ‚úÖ YA IMPLEMENTADO

**Archivos:**
- `frontend/components/screening/full-text-review.tsx`
- `backend/src/domain/models/reference.model.js`

#### 1. **Gesti√≥n de PDFs** ‚úÖ

```tsx
// Subir PDF por referencia
handleFileUpload = async (referenceId: string, file: File) => {
  const formData = new FormData();
  formData.append('pdf', file);
  formData.append('referenceId', referenceId);
  // TODO: Implementar endpoint backend
}
```

**Estado:**
- ‚úÖ UI para subir PDFs (drag & drop / bot√≥n)
- ‚úÖ Validaci√≥n de tipo archivo (solo PDF)
- ‚úÖ Progress bar general (X de Y art√≠culos con PDF)
- ‚úÖ Estados visuales (con PDF / sin PDF)
- ‚ùå **Backend endpoint NO implementado** (almacenamiento de archivos)

#### 2. **Modelo de Datos** ‚úÖ

```javascript
// reference.model.js tiene campos:
fullTextAvailable: boolean
fullTextUrl: string
manualReviewStatus: string
manualReviewNotes: string
reviewedBy: string
reviewedAt: timestamp
```

### ‚ùå NO IMPLEMENTADO

#### **Sistema de Puntuaci√≥n y Checklist** ‚ùå‚ùå‚ùå **CR√çTICO**

**Requerimiento del Docente:**

```javascript
// Checklist esperado por referencia
{
  "studyId": "abc123",
  "user": "stefanny",
  "stage": "fulltext",
  "scores": {
    "relevance": 2,              // 0-2
    "intervention_present": 2,    // 0-2
    "method_validity": 1,         // 0-2
    "data_reported": 2,           // 0-2
    "text_accessible": 1,         // 0-1
    "date_range": 1,              // 0-1
    "method_quality": 1           // 0-2
  },
  "totalScore": 10,               // Suma de scores
  "decision": "include",          // include/exclude basado en threshold
  "threshold": 7,                 // Umbral m√≠nimo (7/12)
  "reason": null,                 // Si exclude, motivo
  "comment": "Buen estudio comparativo",
  "timestamp": "2025-12-03T..."
}
```

**IMPLEMENTAR:**

### 1. **Modelo de Screening Record** (Nuevo)

```javascript
// backend/src/domain/models/screening-record.model.js
const mongoose = require('mongoose');

const screeningRecordSchema = new mongoose.Schema({
  referenceId: { type: mongoose.Schema.Types.ObjectId, ref: 'Reference', required: true },
  projectId: { type: mongoose.Schema.Types.ObjectId, ref: 'Project', required: true },
  userId: { type: mongoose.Schema.Types.ObjectId, ref: 'User', required: true },
  
  stage: { 
    type: String, 
    enum: ['title_abstract', 'fulltext'], 
    required: true 
  },
  
  // Puntajes individuales
  scores: {
    relevance: { type: Number, min: 0, max: 2, default: 0 },
    interventionPresent: { type: Number, min: 0, max: 2, default: 0 },
    methodValidity: { type: Number, min: 0, max: 2, default: 0 },
    dataReported: { type: Number, min: 0, max: 2, default: 0 },
    textAccessible: { type: Number, min: 0, max: 1, default: 0 },
    dateRange: { type: Number, min: 0, max: 1, default: 0 },
    methodQuality: { type: Number, min: 0, max: 2, default: 0 }
  },
  
  totalScore: { type: Number, required: true },
  threshold: { type: Number, default: 7 }, // Ajustable
  
  decision: { 
    type: String, 
    enum: ['include', 'exclude'], 
    required: true 
  },
  
  exclusionReasons: [{ type: String }], // Si exclude, motivos
  comment: { type: String },
  
  reviewedAt: { type: Date, default: Date.now }
}, { 
  timestamps: true 
});

module.exports = mongoose.model('ScreeningRecord', screeningRecordSchema);
```

### 2. **Use Case para Evaluaci√≥n Full-Text**

```javascript
// backend/src/domain/use-cases/evaluate-fulltext.use-case.js
class EvaluateFullTextUseCase {
  constructor({ screeningRecordRepository, referenceRepository }) {
    this.screeningRecordRepository = screeningRecordRepository;
    this.referenceRepository = referenceRepository;
  }

  async execute({ referenceId, userId, projectId, scores, threshold = 7, comment = '' }) {
    // 1. Validar que referencia existe y tiene fulltext
    const reference = await this.referenceRepository.findById(referenceId);
    if (!reference) throw new Error('Referencia no encontrada');
    if (!reference.fullTextAvailable) {
      throw new Error('No hay texto completo disponible para evaluar');
    }

    // 2. Calcular puntaje total
    const totalScore = Object.values(scores).reduce((sum, val) => sum + val, 0);

    // 3. Determinar decisi√≥n basada en threshold
    const decision = totalScore >= threshold ? 'include' : 'exclude';

    // 4. Si es exclusi√≥n, identificar razones principales
    const exclusionReasons = [];
    if (decision === 'exclude') {
      if (scores.relevance < 1) exclusionReasons.push('Tema no relacionado');
      if (scores.methodValidity < 1) exclusionReasons.push('Metodolog√≠a no v√°lida');
      if (scores.dataReported < 1) exclusionReasons.push('No reporta datos emp√≠ricos');
      if (scores.dateRange === 0) exclusionReasons.push('Fuera de rango temporal');
      if (scores.textAccessible === 0) exclusionReasons.push('Texto completo no accesible');
    }

    // 5. Crear screening record
    const record = await this.screeningRecordRepository.create({
      referenceId,
      projectId,
      userId,
      stage: 'fulltext',
      scores,
      totalScore,
      threshold,
      decision,
      exclusionReasons,
      comment
    });

    // 6. Actualizar referencia
    await this.referenceRepository.update(referenceId, {
      screeningStatus: decision === 'include' ? 'included' : 'excluded',
      screeningScore: totalScore,
      exclusionReason: exclusionReasons.join('; '),
      manualReviewStatus: 'completed',
      reviewedBy: userId,
      reviewedAt: new Date()
    });

    return {
      success: true,
      record,
      decision,
      totalScore,
      threshold
    };
  }
}

module.exports = EvaluateFullTextUseCase;
```

### 3. **Frontend: Componente de Evaluaci√≥n Full-Text**

```tsx
// frontend/components/screening/fulltext-evaluation-form.tsx
"use client"

import { useState } from "react"
import { Card, CardContent, CardHeader, CardTitle } from "@/components/ui/card"
import { Button } from "@/components/ui/button"
import { Label } from "@/components/ui/label"
import { Textarea } from "@/components/ui/textarea"
import { Slider } from "@/components/ui/slider"
import { Badge } from "@/components/ui/badge"
import { CheckCircle, XCircle } from "lucide-react"

interface FullTextEvaluationFormProps {
  reference: Reference
  projectId: string
  onSubmit: (evaluation: any) => void
}

export function FullTextEvaluationForm({ reference, projectId, onSubmit }: FullTextEvaluationFormProps) {
  const [scores, setScores] = useState({
    relevance: 0,
    interventionPresent: 0,
    methodValidity: 0,
    dataReported: 0,
    textAccessible: 0,
    dateRange: 0,
    methodQuality: 0
  })
  const [comment, setComment] = useState("")
  const threshold = 7
  
  const totalScore = Object.values(scores).reduce((sum, val) => sum + val, 0)
  const decision = totalScore >= threshold ? 'include' : 'exclude'

  const handleSubmit = () => {
    onSubmit({
      referenceId: reference.id,
      projectId,
      scores,
      threshold,
      comment,
      decision,
      totalScore
    })
  }

  return (
    <Card className="w-full">
      <CardHeader>
        <CardTitle className="flex items-center justify-between">
          <span>Evaluaci√≥n de Texto Completo</span>
          <Badge variant={decision === 'include' ? 'default' : 'destructive'}>
            {decision === 'include' ? (
              <><CheckCircle className="h-3 w-3 mr-1" /> INCLUIR</>
            ) : (
              <><XCircle className="h-3 w-3 mr-1" /> EXCLUIR</>
            )}
          </Badge>
        </CardTitle>
        <p className="text-sm text-muted-foreground">
          Puntaje Total: <strong>{totalScore}/12</strong> | Umbral: {threshold}/12
        </p>
      </CardHeader>
      <CardContent className="space-y-6">
        {/* Relevancia Tem√°tica */}
        <div className="space-y-2">
          <div className="flex justify-between">
            <Label>1. Relevancia Tem√°tica</Label>
            <Badge variant="outline">{scores.relevance}/2</Badge>
          </div>
          <Slider
            value={[scores.relevance]}
            onValueChange={([val]) => setScores({ ...scores, relevance: val })}
            min={0}
            max={2}
            step={1}
          />
          <p className="text-xs text-muted-foreground">
            0=No relevante | 1=Parcialmente | 2=Claramente relevante
          </p>
        </div>

        {/* Intervenci√≥n Presente */}
        <div className="space-y-2">
          <div className="flex justify-between">
            <Label>2. Intervenci√≥n Presente (si aplica PICO)</Label>
            <Badge variant="outline">{scores.interventionPresent}/2</Badge>
          </div>
          <Slider
            value={[scores.interventionPresent]}
            onValueChange={([val]) => setScores({ ...scores, interventionPresent: val })}
            min={0}
            max={2}
            step={1}
          />
        </div>

        {/* Metodolog√≠a V√°lida */}
        <div className="space-y-2">
          <div className="flex justify-between">
            <Label>3. Metodolog√≠a V√°lida</Label>
            <Badge variant="outline">{scores.methodValidity}/2</Badge>
          </div>
          <Slider
            value={[scores.methodValidity]}
            onValueChange={([val]) => setScores({ ...scores, methodValidity: val })}
            min={0}
            max={2}
            step={1}
          />
          <p className="text-xs text-muted-foreground">
            Estudio emp√≠rico, revisi√≥n, caso, etc. bien dise√±ado
          </p>
        </div>

        {/* Datos Reportados */}
        <div className="space-y-2">
          <div className="flex justify-between">
            <Label>4. Datos/Resultados Reportados</Label>
            <Badge variant="outline">{scores.dataReported}/2</Badge>
          </div>
          <Slider
            value={[scores.dataReported]}
            onValueChange={([val]) => setScores({ ...scores, dataReported: val })}
            min={0}
            max={2}
            step={1}
          />
        </div>

        {/* Texto Accesible */}
        <div className="space-y-2">
          <div className="flex justify-between">
            <Label>5. Texto Completo Accesible y Claro</Label>
            <Badge variant="outline">{scores.textAccessible}/1</Badge>
          </div>
          <Slider
            value={[scores.textAccessible]}
            onValueChange={([val]) => setScores({ ...scores, textAccessible: val })}
            min={0}
            max={1}
            step={1}
          />
        </div>

        {/* Rango de Fecha */}
        <div className="space-y-2">
          <div className="flex justify-between">
            <Label>6. Fecha Dentro del Rango</Label>
            <Badge variant="outline">{scores.dateRange}/1</Badge>
          </div>
          <Slider
            value={[scores.dateRange]}
            onValueChange={([val]) => setScores({ ...scores, dateRange: val })}
            min={0}
            max={1}
            step={1}
          />
        </div>

        {/* Calidad Metodol√≥gica */}
        <div className="space-y-2">
          <div className="flex justify-between">
            <Label>7. Calidad Metodol√≥gica</Label>
            <Badge variant="outline">{scores.methodQuality}/2</Badge>
          </div>
          <Slider
            value={[scores.methodQuality]}
            onValueChange={([val]) => setScores({ ...scores, methodQuality: val })}
            min={0}
            max={2}
            step={1}
          />
          <p className="text-xs text-muted-foreground">
            Dise√±o, muestra, controles, validez interna
          </p>
        </div>

        {/* Comentarios */}
        <div className="space-y-2">
          <Label>Comentarios Adicionales</Label>
          <Textarea
            value={comment}
            onChange={(e) => setComment(e.target.value)}
            placeholder="Notas sobre la evaluaci√≥n..."
            rows={3}
          />
        </div>

        {/* Bot√≥n Submit */}
        <Button 
          onClick={handleSubmit}
          className="w-full"
          variant={decision === 'include' ? 'default' : 'destructive'}
        >
          {decision === 'include' ? (
            <><CheckCircle className="mr-2 h-4 w-4" /> Incluir Art√≠culo ({totalScore}/12)</>
          ) : (
            <><XCircle className="mr-2 h-4 w-4" /> Excluir Art√≠culo ({totalScore}/12)</>
          )}
        </Button>
      </CardContent>
    </Card>
  )
}
```

### 4. **M√©tricas de Full-Text**

```javascript
// En analyze-screening-results.use-case.js - agregar secci√≥n de full-text
async analyzeFullText(projectId) {
  const records = await this.screeningRecordRepository.findByProject(projectId, {
    stage: 'fulltext'
  });

  const stats = {
    total: records.length,
    included: records.filter(r => r.decision === 'include').length,
    excluded: records.filter(r => r.decision === 'exclude').length,
    
    // Distribuci√≥n de puntajes
    scoreDistribution: {
      mean: 0,
      median: 0,
      stdDev: 0,
      histogram: [] // Bins: 0-2, 3-4, 5-6, 7-8, 9-10, 11-12
    },
    
    // Motivos de exclusi√≥n (frecuencia)
    exclusionReasons: {},
    
    // Inclusion Yield
    inclusionYield: 0 // (included / total) * 100
  };

  // Calcular estad√≠sticas de puntajes
  const scores = records.map(r => r.totalScore);
  stats.scoreDistribution.mean = scores.reduce((a,b) => a+b, 0) / scores.length;
  stats.scoreDistribution.median = this._median(scores);
  stats.scoreDistribution.stdDev = this._stdDev(scores);

  // Histograma
  const bins = [0, 3, 5, 7, 9, 11];
  stats.scoreDistribution.histogram = bins.map((min, i) => {
    const max = bins[i + 1] || 12;
    return {
      range: `${min}-${max}`,
      count: scores.filter(s => s >= min && s <= max).length
    };
  });

  // Motivos de exclusi√≥n
  records.filter(r => r.decision === 'exclude').forEach(r => {
    r.exclusionReasons.forEach(reason => {
      stats.exclusionReasons[reason] = (stats.exclusionReasons[reason] || 0) + 1;
    });
  });

  // Inclusion Yield
  stats.inclusionYield = ((stats.included / stats.total) * 100).toFixed(2);

  return stats;
}
```

### üìà Completitud: **40%**

**PRIORIDAD CR√çTICA - Implementar:**
1. ‚ùå Modelo `ScreeningRecord` (MongoDB/PostgreSQL)
2. ‚ùå Use Case `EvaluateFullTextUseCase`
3. ‚ùå Repository `ScreeningRecordRepository`
4. ‚ùå Componente `FullTextEvaluationForm` con sliders de puntuaci√≥n
5. ‚ùå Endpoint POST `/api/projects/:id/references/:refId/evaluate-fulltext`
6. ‚ùå Integrar formulario en `full-text-review.tsx`
7. ‚ùå M√©tricas: distribuci√≥n de puntajes, histograma, motivos de exclusi√≥n
8. ‚ùå Exportar `excluded_fulltext.csv` con motivos

---

## üìä FASE 4: An√°lisis de Resultados y Preparaci√≥n para el Art√≠culo

### ‚úÖ YA IMPLEMENTADO

#### 1. **Diagrama PRISMA** ‚úÖ

**Archivo:** `frontend/components/screening/prisma-flow-diagram.tsx`

```tsx
interface PrismaFlowDiagramProps {
  stats: {
    identified: number
    duplicates: number
    afterDedup: number
    screenedTitleAbstract: number
    excludedTitleAbstract: number
    fullTextAssessed: number
    excludedFullText: number
    includedFinal: number
  }
}
```

**Caracter√≠sticas:**
- ‚úÖ Visualizaci√≥n del flujo PRISMA 2020
- ‚úÖ 4 fases: Identificaci√≥n ‚Üí Dedup ‚Üí Cribado ‚Üí Elegibilidad
- ‚úÖ N√∫meros actualizados din√°micamente
- ‚úÖ Porcentajes calculados autom√°ticamente
- ‚ùå **NO genera imagen PNG exportable**

#### 2. **Exportaci√≥n de Referencias** ‚úÖ

**Archivo:** `backend/src/domain/use-cases/export-references.use-case.js`

```javascript
async execute(projectId, format = 'csv', filters = {}) {
  // Formatos: CSV, JSON
  // Filtros: por status, source, etc.
}
```

**Caracter√≠sticas:**
- ‚úÖ Exporta a CSV
- ‚úÖ Exporta a JSON
- ‚úÖ Filtros aplicables (status, etc.)
- ‚úÖ Escapa comillas y caracteres especiales en CSV
- ‚ùå **NO exporta motivos de exclusi√≥n en columna separada**
- ‚ùå **NO exporta screening_records** (auditor√≠a)

#### 3. **An√°lisis de Resultados** ‚úÖ

**Archivo:** `backend/src/domain/use-cases/analyze-screening-results.use-case.js`

```javascript
stats = {
  total: N,
  byStatus: { pending, included, excluded, maybe },
  byAIRecommendation: { include, exclude, maybe, none },
  withAI: N,
  avgConfidence: X,
  avgSimilarity: X,
  disagreements: N,
  percentages: { ... }
}
```

**Caracter√≠sticas:**
- ‚úÖ Estad√≠sticas por estado
- ‚úÖ Estad√≠sticas de IA (confidence, similarity)
- ‚úÖ Detecta desacuerdos humano-IA
- ‚úÖ Calcula porcentajes

### ‚ö†Ô∏è PARCIALMENTE IMPLEMENTADO / FALTANTE

#### 1. **Tablas para Manuscrito** ‚ö†Ô∏è

**Requerido:**

**Tabla 1: Resumen del Proceso de Cribado**
```
| Etapa                      | N Procesadas | N Incluidas | N Excluidas | % Inclusion |
|----------------------------|--------------|-------------|-------------|-------------|
| Identificaci√≥n             | 1,282        | -           | -           | -           |
| Despu√©s de dedup           | 1,010        | -           | -           | -           |
| Cribado t√≠tulo/abstract    | 1,010        | 200         | 810         | 19.8%       |
| Full-text evaluado         | 200          | 45          | 155         | 22.5%       |
| **Incluidos Final**        | **45**       | **45**      | **0**       | **100%**    |
```

**Tabla 2: Motivos de Exclusi√≥n (Full-Text)**
```
| Motivo                          | Frecuencia | % sobre Excluidos |
|---------------------------------|------------|-------------------|
| Tema no relacionado             | 60         | 38.7%             |
| Tipo de estudio no v√°lido       | 25         | 16.1%             |
| Texto completo no disponible    | 20         | 12.9%             |
| Fecha fuera de rango            | 20         | 12.9%             |
| No datos emp√≠ricos              | 30         | 19.4%             |
```

**Tabla 3: Estad√≠sticas del Puntaje (Full-Text)**
```
| M√©trica          | Valor |
|------------------|-------|
| Media            | 7.8   |
| Mediana          | 8.0   |
| Desv. Est√°ndar   | 2.1   |
| M√≠nimo           | 2     |
| M√°ximo           | 12    |
| Umbral usado     | 7     |
```

**IMPLEMENTAR:**

```javascript
// backend/src/domain/use-cases/generate-manuscript-tables.use-case.js
class GenerateManuscriptTablesUseCase {
  async execute(projectId) {
    const references = await this.referenceRepository.findByProject(projectId);
    const screeningRecords = await this.screeningRecordRepository.findByProject(projectId);
    
    // Tabla 1: Resumen del Proceso
    const table1 = {
      identification: references.length,
      duplicates: references.filter(r => r.status === 'duplicate').length,
      afterDedup: references.filter(r => r.status !== 'duplicate').length,
      screenedTitleAbstract: references.filter(r => r.aiRecommendation).length,
      excludedTitleAbstract: references.filter(r => r.aiRecommendation === 'exclude').length,
      passedToFullText: references.filter(r => r.status !== 'duplicate' && r.fullTextAvailable).length,
      fullTextEvaluated: screeningRecords.filter(r => r.stage === 'fulltext').length,
      excludedFullText: screeningRecords.filter(r => r.stage === 'fulltext' && r.decision === 'exclude').length,
      includedFinal: screeningRecords.filter(r => r.stage === 'fulltext' && r.decision === 'include').length
    };
    
    // Tabla 2: Motivos de Exclusi√≥n
    const table2 = [];
    const excludedRecords = screeningRecords.filter(r => r.decision === 'exclude');
    const reasonCounts = {};
    
    excludedRecords.forEach(r => {
      r.exclusionReasons.forEach(reason => {
        reasonCounts[reason] = (reasonCounts[reason] || 0) + 1;
      });
    });
    
    Object.entries(reasonCounts).forEach(([reason, count]) => {
      table2.push({
        motivo: reason,
        frecuencia: count,
        porcentaje: ((count / excludedRecords.length) * 100).toFixed(1)
      });
    });
    
    // Tabla 3: Estad√≠sticas de Puntaje
    const scores = screeningRecords.map(r => r.totalScore);
    const table3 = {
      mean: (scores.reduce((a,b) => a+b, 0) / scores.length).toFixed(1),
      median: this._median(scores),
      stdDev: this._stdDev(scores).toFixed(1),
      min: Math.min(...scores),
      max: Math.max(...scores),
      threshold: 7
    };
    
    return { table1, table2, table3 };
  }
}
```

#### 2. **Inter-Rater Reliability (IRR) / Doble Cribado** ‚ùå

**Requerido:**

```javascript
// Modelo: Permitir que 2 usuarios revisen el mismo art√≠culo
{
  referenceId: "abc",
  reviewer1: "user1",
  reviewer1Decision: "include",
  reviewer1Scores: { relevance: 2, ... },
  
  reviewer2: "user2",
  reviewer2Decision: "exclude",
  reviewer2Scores: { relevance: 1, ... },
  
  resolved: false,
  resolvedBy: null,
  finalDecision: null
}

// Calcular Cohen's Kappa
const kappa = this._calculateKappa(agreements, disagreements);
// kappa > 0.8 = excelente
// kappa 0.6-0.8 = bueno
// kappa < 0.6 = pobre
```

**IMPLEMENTAR:**
1. ‚ùå Modelo `DualReviewRecord`
2. ‚ùå Asignar referencias a 2 revisores
3. ‚ùå Detectar discrepancias
4. ‚ùå UI para arbitraje (3er revisor)
5. ‚ùå Calcular Cohen's Kappa
6. ‚ùå Reportar % acuerdo bruto

#### 3. **Exportaciones Espec√≠ficas para Tesis** ‚ö†Ô∏è

**Requerido:**
- ‚úÖ `references.csv` (ya implementado)
- ‚ùå `duplicates.csv` (id_kept, id_removed, similarity, motivo)
- ‚ùå `excluded_with_reasons.csv` (id, title, stage, reasons)
- ‚ùå `screening_records.json` (audit trail completo)
- ‚ùå `prisma_flow.png` (diagrama exportable)
- ‚ùå `score_histogram.png` (distribuci√≥n de puntajes)

**IMPLEMENTAR:**

```javascript
// backend/src/domain/use-cases/export-thesis-artifacts.use-case.js
class ExportThesisArtifactsUseCase {
  async execute(projectId) {
    return {
      'references_all.csv': await this.exportReferencesCSV(projectId),
      'duplicates.csv': await this.exportDuplicatesCSV(projectId),
      'excluded_fulltext.csv': await this.exportExcludedWithReasons(projectId),
      'screening_records.json': await this.exportScreeningRecords(projectId),
      'manuscript_tables.json': await this.generateManuscriptTables(projectId),
      'statistics_summary.json': await this.generateStatistics(projectId)
    };
  }
}
```

#### 4. **Sensibilidad/Especificidad del Auto-Match** ‚ùå

**Requerido (si hay gold standard):**

```javascript
// Si tienes 100 referencias manualmente validadas (gold standard):
const truePositives = autoInclude ‚à© goldInclude
const trueNegatives = autoExclude ‚à© goldExclude
const falsePositives = autoInclude ‚à© goldExclude  // IA dijo incluir pero deb√≠a excluir
const falseNegatives = autoExclude ‚à© goldInclude  // IA dijo excluir pero deb√≠a incluir

const sensitivity = TP / (TP + FN)  // Recall
const specificity = TN / (TN + FP)
const precision = TP / (TP + FP)
const f1Score = 2 * (precision * sensitivity) / (precision + sensitivity)
```

### üìà Completitud: **60%**

**PRIORIDAD MEDIA - Implementar:**
1. ‚ö†Ô∏è Generador de tablas para manuscrito (Tablas 1, 2, 3)
2. ‚ùå Sistema de doble cribado (dual review)
3. ‚ùå C√°lculo de Cohen's Kappa (IRR)
4. ‚ùå Exportaci√≥n `duplicates.csv`
5. ‚ùå Exportaci√≥n `excluded_with_reasons.csv`
6. ‚ùå Exportaci√≥n `screening_records.json`
7. ‚ùå Exportar PRISMA como PNG (usar librer√≠a charts)
8. ‚ùå Histograma de puntajes exportable
9. ‚ùå Sensibilidad/Especificidad (si hay gold standard)

---

## üéØ RESUMEN DE PRIORIDADES

### üî¥ **PRIORIDAD CR√çTICA** (Implementar YA)

1. **Sistema de Puntuaci√≥n Full-Text** ‚ùå
   - Modelo `ScreeningRecord`
   - Use Case `EvaluateFullTextUseCase`
   - Componente UI con sliders (7 criterios)
   - Endpoint POST `/evaluate-fulltext`
   - **Estimado:** 8-10 horas

2. **M√©tricas de Full-Text** ‚ùå
   - Distribuci√≥n de puntajes (mean, median, std dev)
   - Histograma (bins)
   - Tabla de motivos de exclusi√≥n con frecuencias
   - Inclusion Yield
   - **Estimado:** 4 horas

3. **Backend para PDFs** ‚ùå
   - Endpoint POST `/upload-pdf`
   - Almacenamiento (AWS S3, local, o MongoDB GridFS)
   - Actualizar `fullTextAvailable`, `fullTextUrl`
   - **Estimado:** 6 horas

### üü† **PRIORIDAD ALTA** (Siguiente Sprint)

4. **Filtro Boolean por Keywords** ‚ùå
   - Extraer INCLUDE/EXCLUDE keywords del protocolo
   - Match exacto en t√≠tulo + abstract
   - Categorizaci√≥n: `include_auto`, `exclude_auto`, `manual_review`
   - **Estimado:** 6 horas

5. **Resaltar T√©rminos en UI** ‚ùå
   - Funci√≥n `highlightKeywords()`
   - Mostrar t√©rminos matched en abstract durante revisi√≥n
   - **Estimado:** 2 horas

6. **Generador de Tablas para Manuscrito** ‚ö†Ô∏è
   - Use Case `GenerateManuscriptTablesUseCase`
   - Tabla 1: Resumen del proceso
   - Tabla 2: Motivos de exclusi√≥n
   - Tabla 3: Estad√≠sticas de puntajes
   - Endpoint GET `/manuscript-tables`
   - Componente UI para visualizar tablas
   - **Estimado:** 5 horas

### üü° **PRIORIDAD MEDIA** (Futuro)

7. **Exportaciones Espec√≠ficas para Tesis** ‚ö†Ô∏è
   - `duplicates.csv`
   - `excluded_with_reasons.csv`
   - `screening_records.json`
   - **Estimado:** 4 horas

8. **Doble Cribado (IRR)** ‚ùå
   - Modelo `DualReviewRecord`
   - Asignar a 2 revisores
   - Detectar discrepancias
   - UI arbitraje
   - Calcular Cohen's Kappa
   - **Estimado:** 12 horas

9. **PRISMA Exportable como PNG** ‚ùå
   - Usar librer√≠a: `react-to-png`, `html2canvas`, o `Chart.js`
   - Bot√≥n "Descargar Diagrama"
   - **Estimado:** 3 horas

10. **Histograma Exportable** ‚ùå
    - Usar `Chart.js` o `Recharts`
    - Bins: 0-2, 3-4, 5-6, 7-8, 9-10, 11-12
    - Exportar como PNG
    - **Estimado:** 3 horas

### üü¢ **PRIORIDAD BAJA** (Nice to Have)

11. **Sensibilidad/Especificidad** ‚ùå
    - Requiere gold standard (referencias validadas manualmente)
    - Calcular TP, TN, FP, FN
    - Sensitivity, Specificity, Precision, F1
    - **Estimado:** 4 horas (si hay gold standard)

12. **Mejoras a Detecci√≥n de Duplicados** ‚ö†Ô∏è
    - L√≥gica de "mejor metadato"
    - Exportar `duplicates.csv`
    - Match por t√≠tulo+autor+a√±o normalizado
    - **Estimado:** 3 horas

---

## üìã Plan de Implementaci√≥n Sugerido

### **Sprint 1 (Esta Semana)** - Funcionalidad Cr√≠tica
**Objetivo:** Sistema de evaluaci√≥n full-text operacional

```
D√≠a 1-2: Sistema de Puntuaci√≥n
- [ ] Crear modelo ScreeningRecord (MongoDB/PostgreSQL)
- [ ] Crear ScreeningRecordRepository
- [ ] Implementar EvaluateFullTextUseCase
- [ ] Endpoint POST /api/projects/:id/references/:refId/evaluate-fulltext

D√≠a 3-4: Frontend Full-Text
- [ ] Componente FullTextEvaluationForm con 7 sliders
- [ ] Integrar en full-text-review.tsx
- [ ] Actualizar tabla de referencias con scores
- [ ] Mostrar decisi√≥n (include/exclude) y totalScore

D√≠a 5: M√©tricas
- [ ] Implementar an√°lisis de puntajes en analyze-screening-results
- [ ] Calcular distribuci√≥n, histograma, motivos
- [ ] Endpoint GET /api/projects/:id/fulltext-stats
- [ ] Componente UI para mostrar m√©tricas
```

### **Sprint 2 (Pr√≥xima Semana)** - Mejoras de Screening

```
D√≠a 1-2: Filtro por Keywords
- [ ] Use Case KeywordScreeningUseCase
- [ ] Extraer INCLUDE/EXCLUDE del protocolo
- [ ] Integrar en executeHybrid (antes de embeddings)
- [ ] UI para mostrar t√©rminos matched

D√≠a 3: Resaltar T√©rminos
- [ ] Funci√≥n highlightKeywords()
- [ ] Mostrar en individual-review-enhanced
- [ ] Badge con "3 keywords matched"

D√≠a 4-5: Tablas para Manuscrito
- [ ] GenerateManuscriptTablesUseCase
- [ ] Endpoint GET /manuscript-tables
- [ ] Componente ManuscriptTablesView
- [ ] Bot√≥n "Exportar Tablas" (CSV/JSON)
```

### **Sprint 3 (Siguiente)** - Exportaciones y An√°lisis Avanzado

```
D√≠a 1-2: Exportaciones Tesis
- [ ] Exportar duplicates.csv
- [ ] Exportar excluded_with_reasons.csv
- [ ] Exportar screening_records.json
- [ ] ZIP con todos los artifacts

D√≠a 3-5: Doble Cribado (si se requiere)
- [ ] Modelo DualReviewRecord
- [ ] Asignar referencias a 2 usuarios
- [ ] UI para arbitraje
- [ ] C√°lculo de Cohen's Kappa
```

---

## ‚úÖ Checklist de Completitud

### Fase 1: Eliminar Duplicados
- [x] Algoritmo de detecci√≥n por DOI
- [x] Algoritmo Levenshtein para similitud
- [x] Comparaci√≥n de autores
- [x] Marcar como duplicados en DB
- [x] UI para detectar duplicados
- [x] Reporte de grupos
- [ ] Exportar duplicates.csv
- [ ] L√≥gica de "mejor metadato"

### Fase 2: Screening (T√≠tulo/Resumen)
- [x] Sistema h√≠brido (Embeddings + LLM)
- [x] Modelo all-MiniLM-L6-v2
- [x] An√°lisis de distribuci√≥n (Elbow)
- [x] Clasificaci√≥n por confianza (>30%, <10%, zona gris)
- [x] ChatGPT/Gemini para zona gris
- [x] UI completa para screening
- [ ] Filtro boolean por keywords INCLUDE/EXCLUDE
- [ ] Resaltar t√©rminos matched en UI
- [ ] M√©trica de concordancia auto-match vs humano

### Fase 3: Full Screening (Texto Completo)
- [x] UI para subir PDFs
- [x] Validaci√≥n de tipo archivo
- [x] Progress bar
- [x] Campo fullTextAvailable en modelo
- [ ] Backend endpoint para almacenar PDFs
- [ ] Modelo ScreeningRecord con 7 criterios
- [ ] Use Case EvaluateFullTextUseCase
- [ ] Componente FullTextEvaluationForm con sliders
- [ ] Endpoint POST /evaluate-fulltext
- [ ] C√°lculo autom√°tico de decisi√≥n (threshold)
- [ ] M√©tricas: mean, median, std dev, histogram
- [ ] Tabla de motivos de exclusi√≥n

### Fase 4: An√°lisis de Resultados
- [x] Componente PrismaFlowDiagram
- [x] Estad√≠sticas b√°sicas (total, by status, by AI)
- [x] Detecta desacuerdos humano-IA
- [x] Exportar CSV/JSON
- [ ] Generador de Tabla 1 (resumen proceso)
- [ ] Generador de Tabla 2 (motivos exclusi√≥n)
- [ ] Generador de Tabla 3 (estad√≠sticas puntajes)
- [ ] Exportar PRISMA como PNG
- [ ] Exportar histograma como PNG
- [ ] Exportar duplicates.csv
- [ ] Exportar excluded_with_reasons.csv
- [ ] Exportar screening_records.json
- [ ] Cohen's Kappa (IRR)
- [ ] Doble cribado (dual review)
- [ ] Sensibilidad/Especificidad

---

## üí° Recomendaciones Finales

1. **FOCO INMEDIATO:** Implementar sistema de puntuaci√≥n full-text (Sprint 1). Es la pieza m√°s cr√≠tica que falta.

2. **ITERACI√ìN R√ÅPIDA:** Implementa funcionalidades una por una, prueba, y despliega. No intentes hacer todo a la vez.

3. **VALIDACI√ìN CON EL DOCENTE:** Una vez implementes el sistema de puntuaci√≥n, mu√©strale el checklist y pide feedback sobre los criterios (relevance, methodValidity, etc.). Ajusta seg√∫n su recomendaci√≥n.

4. **DOCUMENTACI√ìN:** Guarda screenshots de cada fase, tablas generadas, y estad√≠sticas. Esto ir√° directo a tu tesis.

5. **GOLD STANDARD:** Si tu docente requiere calcular sensibilidad/especificidad, necesitar√°s crear un conjunto de ~100 referencias manualmente validadas como "gold standard".

6. **UMBRAL AJUSTABLE:** El threshold de 7/12 debe ser configurable por el usuario. Permite que tu docente decida si usa 6/12 o 8/12 seg√∫n la naturaleza del estudio.

---

## üéì Alineaci√≥n con Requerimientos del Docente

| Requerimiento | Estado | Notas |
|---------------|--------|-------|
| Eliminar duplicados (DOI, t√≠tulo+autor, Levenshtein) | ‚úÖ 95% | Falta exportar CSV y l√≥gica de metadatos |
| Screening con t√©rminos del protocolo (INCLUDE/EXCLUDE) | ‚ö†Ô∏è 70% | Falta filtro boolean expl√≠cito |
| Full screening con puntaje (0-12 con threshold 7) | ‚ùå 40% | **FALTA IMPLEMENTAR SISTEMA COMPLETO** |
| M√©tricas: mean, median, std dev, histograma | ‚ùå 0% | Requiere sistema de puntajes primero |
| PRISMA con n√∫meros | ‚úÖ 85% | Falta exportar como PNG |
| Tablas para manuscrito | ‚ö†Ô∏è 50% | Estructura lista, falta generador autom√°tico |
| IRR (Cohen's Kappa) | ‚ùå 0% | Requiere doble cribado |
| Exportaciones (CSV, JSON, audit trail) | ‚ö†Ô∏è 60% | CSV b√°sico listo, faltan exports espec√≠ficos |

---

## üìû Siguiente Paso

**DECISI√ìN REQUERIDA:** ¬øQuieres que empiece a implementar el sistema de puntuaci√≥n full-text (Sprint 1)? 

Si dices **"s√≠"**, proceder√© a crear:
1. Modelo `ScreeningRecord`
2. Use Case `EvaluateFullTextUseCase`
3. Repository `ScreeningRecordRepository`
4. Componente `FullTextEvaluationForm`
5. Endpoint `/evaluate-fulltext`

**Tiempo estimado:** 8-10 horas de desarrollo.

¬øProcedemos? üöÄ
