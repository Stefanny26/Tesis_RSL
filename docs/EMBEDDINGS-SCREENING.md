# Sistema de Cribado con Embeddings - Thesis RSL

##  Descripci贸n

Este sistema implementa cribado autom谩tico de referencias bibliogr谩ficas utilizando **embeddings sem谩nticos** y **similitud de coseno**, basado en la metodolog铆a descrita en el notebook ACEDE-ECN.

##  Caracter铆sticas

### Dos M茅todos de Cribado

1. **Embeddings Sem谩nticos** (Recomendado)
   - Modelo: `all-MiniLM-L6-v2` (384 tokens)
   - Velocidad: ~3 minutos por 1000 referencias
   - Sin costo de API
   - Resultados consistentes y reproducibles

2. **An谩lisis con LLM** (Gemini)
   - An谩lisis contextual profundo
   - Genera explicaciones detalladas
   - Mayor precisi贸n en casos ambiguos
   - Consume cuota de API

##  C贸mo Funciona (Embeddings)

### 1. Generaci贸n de Embeddings

El sistema convierte texto en vectores num茅ricos de 384 dimensiones:

```javascript
// Texto del protocolo PICO
const categoryText = `
  Pregunta: ${researchQuestion}
  Poblaci贸n: ${population}
  Intervenci贸n: ${intervention}
  Comparaci贸n: ${comparison}
  Resultado: ${outcome}
  Criterios de inclusi贸n: ${inclusionCriteria.join('; ')}
  Criterios de exclusi贸n: ${exclusionCriteria.join('; ')}
`

// Texto de la referencia
const referenceText = `
  ${reference.title}
  ${reference.abstract}
  Keywords: ${reference.keywords.join(', ')}
`

// Generar embeddings
const categoryEmbedding = await model.encode(categoryText)
const referenceEmbedding = await model.encode(referenceText)
```

### 2. C谩lculo de Similitud de Coseno

```javascript
function cosineSimilarity(vecA, vecB) {
  let dotProduct = 0
  let normA = 0
  let normB = 0
  
  for (let i = 0; i < vecA.length; i++) {
    dotProduct += vecA[i] * vecB[i]
    normA += vecA[i] * vecA[i]
    normB += vecB[i] * vecB[i]
  }
  
  return dotProduct / (Math.sqrt(normA) * Math.sqrt(normB))
}
```

### 3. Clasificaci贸n por Umbral

```javascript
const similarity = cosineSimilarity(categoryEmbedding, referenceEmbedding)
const recommendation = similarity >= threshold ? 'include' : 'exclude'
```

##  Endpoints API

### 1. Cribado Individual con Embeddings

```http
POST /api/ai/screen-reference-embeddings
Content-Type: application/json
Authorization: Bearer <token>

{
  "reference": {
    "id": "ref-123",
    "title": "Machine Learning in Healthcare",
    "abstract": "This study investigates...",
    "keywords": ["ML", "healthcare", "AI"]
  },
  "protocol": {
    "researchQuestion": "How does ML improve healthcare?",
    "population": "Healthcare providers",
    "intervention": "Machine Learning systems",
    "comparison": "Traditional methods",
    "outcome": "Patient outcomes",
    "inclusionCriteria": ["Published 2015-2024", "Peer-reviewed"],
    "exclusionCriteria": ["Non-English", "Opinion pieces"]
  },
  "threshold": 0.7
}
```

**Respuesta:**

```json
{
  "success": true,
  "data": {
    "referenceId": "ref-123",
    "similarity": 0.8456,
    "threshold": 0.7,
    "recommendation": "include",
    "confidence": 0.485,
    "reasoning": "La similitud sem谩ntica es de 84.6%, superando el umbral del 70%..."
  }
}
```

### 2. Cribado en Lote con Embeddings

```http
POST /api/ai/screen-references-batch-embeddings
Content-Type: application/json
Authorization: Bearer <token>

{
  "references": [/* array de referencias */],
  "protocol": {/* protocolo PICO */},
  "threshold": 0.7
}
```

**Respuesta:**

```json
{
  "success": true,
  "data": [
    {
      "success": true,
      "referenceId": "ref-1",
      "similarity": 0.8456,
      "recommendation": "include",
      "reasoning": "..."
    },
    // ...m谩s resultados
  ],
  "summary": {
    "total": 150,
    "successful": 150,
    "failed": 0,
    "toInclude": 45,
    "toExclude": 105,
    "avgSimilarity": 0.6234,
    "percentageToInclude": "30.0"
  }
}
```

### 3. Ranking de Referencias

```http
POST /api/ai/ranking-embeddings
Content-Type: application/json
Authorization: Bearer <token>

{
  "references": [/* array de referencias */],
  "protocol": {/* protocolo PICO */},
  "models": ["Xenova/all-MiniLM-L6-v2"] // opcional
}
```

**Respuesta:**

```json
{
  "success": true,
  "data": [
    {
      "referenceId": "ref-42",
      "referenceTitle": "Deep Learning for Medical Diagnosis",
      "avgSimilarity": 0.9123,
      "rankings": [
        {
          "model": "Xenova/all-MiniLM-L6-v2",
          "similarity": 0.9123
        }
      ]
    },
    // ...m谩s referencias ordenadas por similitud
  ],
  "modelsUsed": ["Xenova/all-MiniLM-L6-v2"]
}
```

##  Componentes Frontend

### 1. AIScreeningPanel

Panel con dos pesta帽as para seleccionar m茅todo:

```tsx
<AIScreeningPanel
  totalReferences={150}
  pendingReferences={100}
  onRunScreening={(threshold, method) => {
    // 'embeddings' o 'llm'
  }}
/>
```

### 2. RankingView

Vista de ranking con referencias ordenadas por similitud:

```tsx
<RankingView
  rankings={rankingData}
  threshold={0.7}
  onAccept={(refId) => handleInclude(refId)}
  onReject={(refId) => handleExclude(refId)}
/>
```

##  Configuraci贸n

### Variables de Entorno

```env
# Backend (.env)
OPENAI_API_KEY=sk-proj-...  # Para m茅todo LLM (opcional)
GEMINI_API_KEY=...           # Para m茅todo LLM (opcional)
```

### Instalaci贸n de Dependencias

```bash
# Backend
cd backend
npm install

# El paquete @xenova/transformers se instala autom谩ticamente
```

##  M茅tricas de Rendimiento

| M茅todo | Velocidad | Costo | Reproducibilidad | Explicaci贸n |
|--------|-----------|-------|------------------|-------------|
| **Embeddings** | 3 min/1000 refs | Gratis | 100% | No |
| **LLM (Gemini)** | 10-15 min/1000 refs | $0.01/1000 refs | ~95% | S铆 |

##  Umbrales Recomendados

| Umbral | Uso Recomendado | Precisi贸n | Recall |
|--------|-----------------|-----------|--------|
| **0.8-0.95** | Primera criba (conservador) | Alta | Baja |
| **0.7-0.8** | Balance 贸ptimo (recomendado) | Media | Media |
| **0.5-0.7** | Segunda criba (liberal) | Baja | Alta |

##  Ejemplo de Uso Completo

### Paso 1: Definir Protocolo PICO

```javascript
const protocol = {
  researchQuestion: "驴C贸mo afecta el machine learning a los diagn贸sticos m茅dicos?",
  selectedTitle: "Machine Learning en Diagn贸stico M茅dico: RSL",
  population: "Profesionales de la salud",
  intervention: "Sistemas de ML",
  comparison: "M茅todos tradicionales",
  outcome: "Precisi贸n diagn贸stica",
  inclusionCriteria: [
    "Publicaciones 2015-2024",
    "Revisi贸n por pares",
    "Estudios emp铆ricos"
  ],
  exclusionCriteria: [
    "No publicados",
    "Opiniones sin datos",
    "Idioma no ingl茅s"
  ]
}
```

### Paso 2: Ejecutar Cribado

```typescript
const result = await apiClient.screenReferencesBatchWithEmbeddings({
  references: myReferences,
  protocol: protocol,
  threshold: 0.7
})

console.log(`Procesadas: ${result.summary.total}`)
console.log(`A incluir: ${result.summary.toInclude}`)
console.log(`A excluir: ${result.summary.toExclude}`)
console.log(`Similitud promedio: ${(result.summary.avgSimilarity * 100).toFixed(1)}%`)
```

### Paso 3: Revisar Ranking

```typescript
const ranking = await apiClient.generateRankingWithEmbeddings({
  references: myReferences,
  protocol: protocol
})

// Top 10 referencias m谩s relevantes
ranking.data.slice(0, 10).forEach((item, idx) => {
  console.log(`${idx + 1}. ${item.referenceTitle}`)
  console.log(`   Similitud: ${(item.avgSimilarity * 100).toFixed(1)}%`)
})
```

##  Referencias

- **Modelo:** [sentence-transformers/all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)
- **Librer铆a:** [@xenova/transformers](https://www.npmjs.com/package/@xenova/transformers)
- **Metodolog铆a:** Basado en notebook ACEDE-ECN workshop dic-2024

##  Troubleshooting

### Error: "No se pudo inicializar el modelo de embeddings"

**Soluci贸n:** El modelo se descarga autom谩ticamente la primera vez. Aseg煤rate de tener:
- Conexi贸n a internet
- Espacio en disco (~100MB para el modelo)
- Permisos de escritura en el directorio cache

### Error: "Los vectores deben tener la misma dimensi贸n"

**Soluci贸n:** Esto indica que se intentaron comparar embeddings de diferentes modelos. Aseg煤rate de usar el mismo modelo para generar todos los embeddings.

### Rendimiento lento

**Soluci贸n:**
- El modelo se descarga solo la primera vez
- Procesamiento en batch es m谩s eficiente
- Para miles de referencias, considera ejecutar por lotes de 500-1000

##  Cr茅ditos

Implementado por: Stefanny Hern谩ndez  
Basado en: Metodolog铆a ACEDE-ECN workshop dic-2024  
Modelo: Sentence Transformers (Hugging Face)  
Framework: Next.js + Express + PostgreSQL
